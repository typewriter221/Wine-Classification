{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine Classification-ML Assignment",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN3-V8N0CZvu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Assignment - Wine Classification\n",
        "---\n",
        "\n",
        "\n",
        "#**Naman Kaushik**\n",
        "# **17134020**\n",
        "# **Mechanical Engineering Part-III**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilhpIZEcJbDd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bc94feb0-3909-42c4-ee3c-9ff327304d24"
      },
      "source": [
        "# Importing Required Libraries and Functions\n",
        "import pandas as pd\n",
        "from keras import Model\n",
        "from keras import Sequential \n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Input, activations, optimizers\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8vI6IjaDdac",
        "colab_type": "text"
      },
      "source": [
        "# **Wine Classification**\n",
        "##[Dataset](https://archive.ics.uci.edu/ml/datasets/Wine)\n",
        "## Number Classes - 3\n",
        "## Nuber of Features - 13\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8OqEsTbcsop",
        "colab": {}
      },
      "source": [
        "# Loading Data \n",
        "df = pd.read_csv('/content/drive/My Drive/ML-Assignment/wine.csv', header = None)\n",
        "# Shuffeling Data\n",
        "df.sample(frac=1).reset_index(drop=True)\n",
        "Y = (df.iloc[:,:1]).to_numpy()\n",
        "X = (df.iloc[:,1:14]).to_numpy()\n",
        "Y = Y-1\n",
        "# One-hot representing the classes\n",
        "Y = to_categorical(Y)\n",
        "# Spliting test and train data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.30, random_state=42)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FESmRsaC-zdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of parameter tuples [learning rate, number of neurons in hidden layer 10 different combinations\n",
        "hyper_para = [[1e-3,26],[1e-3,52],[1e-3,104],[1e-3,208],[1e-2,26],[1e-3,52],[1e-3,104],[1e-3,208],[5e-3,104],[5e-3,208]]\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTYRz_cJ97fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create the model\n",
        "# 13->neurons_hidden_layer->3(classes)\n",
        "def classification_model(n_neurons):\n",
        "  inputs = Input(shape=(13,))\n",
        "  x = Dense(n_neurons,activation='relu')(inputs)\n",
        "  out = Dense(3,activation='softmax')(x)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=out)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQ_fTj19nS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15f83b1d-0106-46ef-f446-1e53af0a8521"
      },
      "source": [
        "# KFold Cross validation on the model by intialzing it randomly 20 times with 10 different model parameter\n",
        "acc = []\n",
        "\n",
        "for learning_rate, n_neurons in hyper_para:\n",
        "  best_acc = 0\n",
        "  for i in range(20):\n",
        "    model = classification_model(n_neurons)\n",
        "    opt = optimizers.Adam(lr = learning_rate)\n",
        "    model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    kfold = KFold(n_splits = 3 , shuffle = True)\n",
        "    for train, test in kfold.split(X_train,Y_train):\n",
        "      history = model.fit( X_train[train], Y_train[train],batch_size=10,verbose=2,shuffle= True)\n",
        "      scores = model.evaluate(X_train[test], Y_train[test],verbose=2)\n",
        "      loss = scores[0]\n",
        "      loss_dif = 1\n",
        "      epoch = 1\n",
        "      while loss_dif>1e-5:\n",
        "        history = model.fit( X_train[train], Y_train[train],batch_size=10,verbose=0,shuffle= True)\n",
        "        scores = model.evaluate(X_train[test], Y_train[test],verbose=0)\n",
        "        loss_dif = loss - scores[0]\n",
        "        loss = scores[0]\n",
        "        epoch +=1\n",
        "        # if epoch>250:\n",
        "        #   break\n",
        "      if scores[1]>best_acc:\n",
        "        best_acc = scores[1]\n",
        "        best_epoch = epoch\n",
        "      print(\"Minimum loss = \",loss)\n",
        "    acc.append([i,best_acc,best_epoch])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 0s - loss: 219.8322 - accuracy: 0.2439\n",
            "Minimum loss =  14.716963540940057\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.9162 - accuracy: 0.4819\n",
            "Minimum loss =  1.2156660382340594\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2314 - accuracy: 0.5542\n",
            "Minimum loss =  0.7047304067669845\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.7390 - accuracy: 0.2805\n",
            "Minimum loss =  4.841940448397682\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.1710 - accuracy: 0.3012\n",
            "Minimum loss =  1.3717357269147548\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1597 - accuracy: 0.3855\n",
            "Minimum loss =  1.4298629004780838\n",
            "Epoch 1/1\n",
            " - 0s - loss: 295.0419 - accuracy: 0.2561\n",
            "Minimum loss =  3.701830432528541\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.1970 - accuracy: 0.3976\n",
            "Minimum loss =  1.2014283930383078\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2158 - accuracy: 0.7229\n",
            "Minimum loss =  1.7603890721390887\n",
            "Epoch 1/1\n",
            " - 0s - loss: 63.8998 - accuracy: 0.3171\n",
            "Minimum loss =  1.9612740675608318\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4781 - accuracy: 0.6265\n",
            "Minimum loss =  1.217893774916486\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2183 - accuracy: 0.6386\n",
            "Minimum loss =  1.2815161420077812\n",
            "Epoch 1/1\n",
            " - 0s - loss: 125.8855 - accuracy: 0.2805\n",
            "Minimum loss =  0.8050525869641986\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6963 - accuracy: 0.7470\n",
            "Minimum loss =  1.1173746207865274\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8139 - accuracy: 0.7831\n",
            "Minimum loss =  0.6873970773161912\n",
            "Epoch 1/1\n",
            " - 0s - loss: 88.7487 - accuracy: 0.3049\n",
            "Minimum loss =  7.761432920183454\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.9512 - accuracy: 0.4217\n",
            "Minimum loss =  1.7940273633817347\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5527 - accuracy: 0.6265\n",
            "Minimum loss =  1.4433069345427723\n",
            "Epoch 1/1\n",
            " - 0s - loss: 140.5268 - accuracy: 0.2683\n",
            "Minimum loss =  9.175283886137462\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.7828 - accuracy: 0.5301\n",
            "Minimum loss =  3.5016314692613557\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.0027 - accuracy: 0.4337\n",
            "Minimum loss =  2.5215273077895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 124.7280 - accuracy: 0.3659\n",
            "Minimum loss =  26.41947991507394\n",
            "Epoch 1/1\n",
            " - 0s - loss: 26.4981 - accuracy: 0.2410\n",
            "Minimum loss =  1.7642177750424641\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8051 - accuracy: 0.3735\n",
            "Minimum loss =  1.3040877667869009\n",
            "Epoch 1/1\n",
            " - 0s - loss: 275.5685 - accuracy: 0.3902\n",
            "Minimum loss =  12.460154715038481\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.2470 - accuracy: 0.4337\n",
            "Minimum loss =  2.8917585117060964\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2411 - accuracy: 0.4096\n",
            "Minimum loss =  1.5285489123042038\n",
            "Epoch 1/1\n",
            " - 0s - loss: 31.0126 - accuracy: 0.3171\n",
            "Minimum loss =  1.3249133371171498\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1118 - accuracy: 0.6747\n",
            "Minimum loss =  0.9059889850819983\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8558 - accuracy: 0.6988\n",
            "Minimum loss =  0.8856954400132342\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.2627 - accuracy: 0.2805\n",
            "Minimum loss =  0.9293362214451745\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4999 - accuracy: 0.5060\n",
            "Minimum loss =  1.0602592753200997\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9478 - accuracy: 0.6386\n",
            "Minimum loss =  1.7221812271490329\n",
            "Epoch 1/1\n",
            " - 0s - loss: 88.3475 - accuracy: 0.3415\n",
            "Minimum loss =  6.3656650724865145\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5585 - accuracy: 0.3494\n",
            "Minimum loss =  1.8578744109083967\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7036 - accuracy: 0.5181\n",
            "Minimum loss =  1.12476318493122\n",
            "Epoch 1/1\n",
            " - 0s - loss: 150.1313 - accuracy: 0.4146\n",
            "Minimum loss =  8.05906831650507\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4202 - accuracy: 0.1687\n",
            "Minimum loss =  1.0687007715062398\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0014 - accuracy: 0.6145\n",
            "Minimum loss =  0.7053996731595296\n",
            "Epoch 1/1\n",
            " - 0s - loss: 142.7928 - accuracy: 0.3537\n",
            "Minimum loss =  3.0195771966661726\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3743 - accuracy: 0.4578\n",
            "Minimum loss =  2.029947792611471\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3376 - accuracy: 0.5542\n",
            "Minimum loss =  1.8484243110912602\n",
            "Epoch 1/1\n",
            " - 0s - loss: 150.6556 - accuracy: 0.3171\n",
            "Minimum loss =  1.9310034456707181\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2122 - accuracy: 0.5301\n",
            "Minimum loss =  2.3362665001938985\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.4410 - accuracy: 0.5181\n",
            "Minimum loss =  1.8402057042936\n",
            "Epoch 1/1\n",
            " - 0s - loss: 67.6260 - accuracy: 0.3902\n",
            "Minimum loss =  1.2104927869070143\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1340 - accuracy: 0.4940\n",
            "Minimum loss =  0.9938563951631871\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7818 - accuracy: 0.6627\n",
            "Minimum loss =  0.49297520590991506\n",
            "Epoch 1/1\n",
            " - 0s - loss: 34.3131 - accuracy: 0.1707\n",
            "Minimum loss =  1.8894110634213401\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2985 - accuracy: 0.6506\n",
            "Minimum loss =  1.0282997794267608\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9855 - accuracy: 0.7108\n",
            "Minimum loss =  0.6675387083030329\n",
            "Epoch 1/1\n",
            " - 0s - loss: 67.5362 - accuracy: 0.3293\n",
            "Minimum loss =  4.587010315486363\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9670 - accuracy: 0.6747\n",
            "Minimum loss =  1.5438896679296725\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5984 - accuracy: 0.6024\n",
            "Minimum loss =  1.2631107568740845\n",
            "Epoch 1/1\n",
            " - 0s - loss: 38.4109 - accuracy: 0.3171\n",
            "Minimum loss =  6.721938110533214\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.6759 - accuracy: 0.0964\n",
            "Minimum loss =  4.988815505330155\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.9921 - accuracy: 0.1807\n",
            "Minimum loss =  2.617795403410749\n",
            "Epoch 1/1\n",
            " - 0s - loss: 96.7234 - accuracy: 0.6220\n",
            "Minimum loss =  1.4311505612872897\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4395 - accuracy: 0.6506\n",
            "Minimum loss =  1.771274752733184\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1963 - accuracy: 0.6747\n",
            "Minimum loss =  1.5645999065259608\n",
            "Epoch 1/1\n",
            " - 0s - loss: 54.3792 - accuracy: 0.2927\n",
            "Minimum loss =  10.847444534301758\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4970 - accuracy: 0.3133\n",
            "Minimum loss =  7.966086643498119\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.2997 - accuracy: 0.2771\n",
            "Minimum loss =  1.1309051339219256\n",
            "Epoch 1/1\n",
            " - 0s - loss: 120.3281 - accuracy: 0.4024\n",
            "Minimum loss =  13.479681105840774\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.0624 - accuracy: 0.0964\n",
            "Minimum loss =  0.7611821933490474\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7461 - accuracy: 0.7229\n",
            "Minimum loss =  0.5787556345869855\n",
            "Epoch 1/1\n",
            " - 0s - loss: 37.0108 - accuracy: 0.2927\n",
            "Minimum loss =  2.9149697621663413\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6949 - accuracy: 0.4819\n",
            "Minimum loss =  0.946480500988844\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0517 - accuracy: 0.6506\n",
            "Minimum loss =  0.61621164694065\n",
            "Epoch 1/1\n",
            " - 0s - loss: 36.6628 - accuracy: 0.3171\n",
            "Minimum loss =  16.337552751813615\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.9592 - accuracy: 0.1325\n",
            "Minimum loss =  6.084700375068478\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.9351 - accuracy: 0.0843\n",
            "Minimum loss =  2.384226612928437\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.6940 - accuracy: 0.1951\n",
            "Minimum loss =  3.023524897439139\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.4141 - accuracy: 0.3855\n",
            "Minimum loss =  1.9119878774735986\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4384 - accuracy: 0.4337\n",
            "Minimum loss =  1.0009906582716035\n",
            "Epoch 1/1\n",
            " - 0s - loss: 29.1926 - accuracy: 0.4390\n",
            "Minimum loss =  1.7431415489741735\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0955 - accuracy: 0.6867\n",
            "Minimum loss =  1.4779774968217059\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2187 - accuracy: 0.6747\n",
            "Minimum loss =  1.6579203053218563\n",
            "Epoch 1/1\n",
            " - 0s - loss: 74.8122 - accuracy: 0.6098\n",
            "Minimum loss =  1.0754081975846064\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8602 - accuracy: 0.6747\n",
            "Minimum loss =  0.9070507695035237\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7312 - accuracy: 0.6988\n",
            "Minimum loss =  0.7660837754970644\n",
            "Epoch 1/1\n",
            " - 0s - loss: 44.0408 - accuracy: 0.3659\n",
            "Minimum loss =  8.13482393537249\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4061 - accuracy: 0.4578\n",
            "Minimum loss =  0.6520624247992911\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7799 - accuracy: 0.7831\n",
            "Minimum loss =  0.7466005930086461\n",
            "Epoch 1/1\n",
            " - 0s - loss: 27.6775 - accuracy: 0.4390\n",
            "Minimum loss =  9.016695113409133\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.8658 - accuracy: 0.4337\n",
            "Minimum loss =  4.051694875810204\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.0817 - accuracy: 0.5422\n",
            "Minimum loss =  1.000542263432247\n",
            "Epoch 1/1\n",
            " - 0s - loss: 186.8943 - accuracy: 0.3780\n",
            "Minimum loss =  3.5985852650233676\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.5264 - accuracy: 0.5542\n",
            "Minimum loss =  2.355302944415953\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5531 - accuracy: 0.5783\n",
            "Minimum loss =  1.2263429339339094\n",
            "Epoch 1/1\n",
            " - 0s - loss: 67.4051 - accuracy: 0.3049\n",
            "Minimum loss =  8.023237182980491\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.9368 - accuracy: 0.2410\n",
            "Minimum loss =  2.042258785992134\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5549 - accuracy: 0.5422\n",
            "Minimum loss =  1.5941245788481178\n",
            "Epoch 1/1\n",
            " - 0s - loss: 170.8123 - accuracy: 0.3537\n",
            "Minimum loss =  4.083493868509929\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8738 - accuracy: 0.6627\n",
            "Minimum loss =  1.9887119386254288\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.1187 - accuracy: 0.6386\n",
            "Minimum loss =  2.3029541387790586\n",
            "Epoch 1/1\n",
            " - 0s - loss: 75.5321 - accuracy: 0.2683\n",
            "Minimum loss =  18.244761875697545\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.9347 - accuracy: 0.3253\n",
            "Minimum loss =  1.0201266458848628\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8388 - accuracy: 0.6024\n",
            "Minimum loss =  0.39642993996783\n",
            "Epoch 1/1\n",
            " - 0s - loss: 132.2097 - accuracy: 0.3171\n",
            "Minimum loss =  5.400978894460769\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9433 - accuracy: 0.6506\n",
            "Minimum loss =  2.1786088536425336\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7895 - accuracy: 0.6988\n",
            "Minimum loss =  2.9609028886004194\n",
            "Epoch 1/1\n",
            " - 0s - loss: 92.2555 - accuracy: 0.3415\n",
            "Minimum loss =  51.49223109654018\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.6473 - accuracy: 0.2892\n",
            "Minimum loss =  1.6255699308907114\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1331 - accuracy: 0.5783\n",
            "Minimum loss =  1.0557096585994814\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.5365 - accuracy: 0.2073\n",
            "Minimum loss =  0.49822244473866056\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3933 - accuracy: 0.8795\n",
            "Minimum loss =  0.3636365838167144\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3790 - accuracy: 0.8795\n",
            "Minimum loss =  0.3527244736508625\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.1514 - accuracy: 0.3171\n",
            "Minimum loss =  10.851187615167527\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.2148 - accuracy: 0.3735\n",
            "Minimum loss =  3.1721277992899823\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7685 - accuracy: 0.4940\n",
            "Minimum loss =  0.8376632376414973\n",
            "Epoch 1/1\n",
            " - 0s - loss: 140.9011 - accuracy: 0.3659\n",
            "Minimum loss =  2.378544739314488\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7108 - accuracy: 0.3494\n",
            "Minimum loss =  1.1793027302113974\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2816 - accuracy: 0.4578\n",
            "Minimum loss =  0.6966491981250483\n",
            "Epoch 1/1\n",
            " - 0s - loss: 169.6562 - accuracy: 0.3780\n",
            "Minimum loss =  5.842080593109131\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5772 - accuracy: 0.4458\n",
            "Minimum loss =  1.4987478430678205\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2625 - accuracy: 0.6145\n",
            "Minimum loss =  0.8426490382450383\n",
            "Epoch 1/1\n",
            " - 0s - loss: 34.2871 - accuracy: 0.3171\n",
            "Minimum loss =  13.280818439665294\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5434 - accuracy: 0.4578\n",
            "Minimum loss =  2.2969609324525044\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2611 - accuracy: 0.6024\n",
            "Minimum loss =  2.092004520137136\n",
            "Epoch 1/1\n",
            " - 0s - loss: 23.0811 - accuracy: 0.3780\n",
            "Minimum loss =  7.912344251360212\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.3930 - accuracy: 0.4578\n",
            "Minimum loss =  5.632453127605159\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9249 - accuracy: 0.6747\n",
            "Minimum loss =  4.910591078967583\n",
            "Epoch 1/1\n",
            " - 0s - loss: 85.2322 - accuracy: 0.3171\n",
            "Minimum loss =  1.551955262819926\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4710 - accuracy: 0.5301\n",
            "Minimum loss =  0.8724207107613726\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8863 - accuracy: 0.6627\n",
            "Minimum loss =  0.9578609873608845\n",
            "Epoch 1/1\n",
            " - 0s - loss: 127.6590 - accuracy: 0.2317\n",
            "Minimum loss =  4.986370449974423\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6358 - accuracy: 0.3614\n",
            "Minimum loss =  0.5974423434676194\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6072 - accuracy: 0.7831\n",
            "Minimum loss =  0.7038593263160892\n",
            "Epoch 1/1\n",
            " - 0s - loss: 64.2040 - accuracy: 0.4146\n",
            "Minimum loss =  2.5993670452208746\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8830 - accuracy: 0.3494\n",
            "Minimum loss =  0.5159873293667305\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.4504 - accuracy: 0.8313\n",
            "Minimum loss =  0.5044112234580808\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.9571 - accuracy: 0.3780\n",
            "Minimum loss =  17.910536902291433\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.9679 - accuracy: 0.4217\n",
            "Minimum loss =  0.9843551443844307\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9884 - accuracy: 0.6627\n",
            "Minimum loss =  1.6937729120254517\n",
            "Epoch 1/1\n",
            " - 0s - loss: 112.3247 - accuracy: 0.4024\n",
            "Minimum loss =  8.137073426019578\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.8884 - accuracy: 0.5181\n",
            "Minimum loss =  1.4576401536057635\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3161 - accuracy: 0.5783\n",
            "Minimum loss =  1.023616175099117\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.5786 - accuracy: 0.3415\n",
            "Minimum loss =  3.257799091793242\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3949 - accuracy: 0.4458\n",
            "Minimum loss =  2.4622080049863677\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6993 - accuracy: 0.4458\n",
            "Minimum loss =  1.7937248567255533\n",
            "Epoch 1/1\n",
            " - 0s - loss: 90.1928 - accuracy: 0.2439\n",
            "Minimum loss =  4.214007491157169\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0653 - accuracy: 0.5181\n",
            "Minimum loss =  2.977576552367792\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.1499 - accuracy: 0.5301\n",
            "Minimum loss =  1.6787403269511898\n",
            "Epoch 1/1\n",
            " - 0s - loss: 67.0250 - accuracy: 0.3049\n",
            "Minimum loss =  7.506117184956868\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0462 - accuracy: 0.5301\n",
            "Minimum loss =  1.6083413042673251\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7122 - accuracy: 0.6145\n",
            "Minimum loss =  1.5402672494330056\n",
            "Epoch 1/1\n",
            " - 0s - loss: 72.8650 - accuracy: 0.2927\n",
            "Minimum loss =  0.4965446385599318\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3767 - accuracy: 0.8795\n",
            "Minimum loss =  0.8427604109775729\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6446 - accuracy: 0.8072\n",
            "Minimum loss =  2.826089463582853\n",
            "Epoch 1/1\n",
            " - 0s - loss: 14.7981 - accuracy: 0.2561\n",
            "Minimum loss =  3.751910062063308\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9369 - accuracy: 0.4217\n",
            "Minimum loss =  0.9003588833459993\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9220 - accuracy: 0.6386\n",
            "Minimum loss =  1.1291512745182688\n",
            "Epoch 1/1\n",
            " - 0s - loss: 71.8485 - accuracy: 0.2561\n",
            "Minimum loss =  4.916814531598773\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.6160 - accuracy: 0.5181\n",
            "Minimum loss =  1.698013928605289\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.1168 - accuracy: 0.6145\n",
            "Minimum loss =  2.6881235052899615\n",
            "Epoch 1/1\n",
            " - 0s - loss: 36.5340 - accuracy: 0.2439\n",
            "Minimum loss =  1.692221312295823\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3657 - accuracy: 0.4578\n",
            "Minimum loss =  1.488459735381894\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9287 - accuracy: 0.5422\n",
            "Minimum loss =  0.929424697306098\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.8791 - accuracy: 0.5122\n",
            "Minimum loss =  0.9131376970381964\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7834 - accuracy: 0.6988\n",
            "Minimum loss =  1.1225756203256003\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8884 - accuracy: 0.6506\n",
            "Minimum loss =  0.6331841960185911\n",
            "Epoch 1/1\n",
            " - 0s - loss: 77.7688 - accuracy: 0.3415\n",
            "Minimum loss =  1.278406131835211\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2216 - accuracy: 0.4940\n",
            "Minimum loss =  1.1498509136641897\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9013 - accuracy: 0.5904\n",
            "Minimum loss =  1.874841678433302\n",
            "Epoch 1/1\n",
            " - 0s - loss: 96.2230 - accuracy: 0.3049\n",
            "Minimum loss =  5.063525018237886\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.4885 - accuracy: 0.5181\n",
            "Minimum loss =  1.502429921452592\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9657 - accuracy: 0.6506\n",
            "Minimum loss =  0.9165432307778335\n",
            "Epoch 1/1\n",
            " - 0s - loss: 108.1538 - accuracy: 0.2805\n",
            "Minimum loss =  0.8505611476444063\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4310 - accuracy: 0.6265\n",
            "Minimum loss =  0.9136427749947804\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9398 - accuracy: 0.7108\n",
            "Minimum loss =  1.1806220979225346\n",
            "Epoch 1/1\n",
            " - 0s - loss: 86.7964 - accuracy: 0.2927\n",
            "Minimum loss =  2.2274540833064487\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.7464 - accuracy: 0.5542\n",
            "Minimum loss =  0.7877483178929585\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8552 - accuracy: 0.6867\n",
            "Minimum loss =  0.6813180621077375\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.8212 - accuracy: 0.2439\n",
            "Minimum loss =  1.7523517182895116\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3179 - accuracy: 0.4940\n",
            "Minimum loss =  2.0918855085605528\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4544 - accuracy: 0.5904\n",
            "Minimum loss =  0.601162776714418\n",
            "Epoch 1/1\n",
            " - 0s - loss: 77.9844 - accuracy: 0.2927\n",
            "Minimum loss =  19.214781624930247\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.7506 - accuracy: 0.4337\n",
            "Minimum loss =  3.6779621752297005\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9690 - accuracy: 0.5783\n",
            "Minimum loss =  3.264797978284882\n",
            "Epoch 1/1\n",
            " - 0s - loss: 73.8535 - accuracy: 0.3049\n",
            "Minimum loss =  22.835327875046502\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.0988 - accuracy: 0.2892\n",
            "Minimum loss =  0.6149706215393252\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6312 - accuracy: 0.7229\n",
            "Minimum loss =  1.4523154846051844\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.0675 - accuracy: 0.3659\n",
            "Minimum loss =  1.1522600877852667\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3480 - accuracy: 0.6265\n",
            "Minimum loss =  1.2961693217114705\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8902 - accuracy: 0.6386\n",
            "Minimum loss =  0.9815517373201323\n",
            "Epoch 1/1\n",
            " - 0s - loss: 89.9741 - accuracy: 0.4146\n",
            "Minimum loss =  24.96968750726609\n",
            "Epoch 1/1\n",
            " - 0s - loss: 22.1551 - accuracy: 0.3012\n",
            "Minimum loss =  1.2493997754120245\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9754 - accuracy: 0.6265\n",
            "Minimum loss =  0.8994517384505853\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.6606 - accuracy: 0.2927\n",
            "Minimum loss =  1.9796662898290724\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2122 - accuracy: 0.6506\n",
            "Minimum loss =  1.03348048140363\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3123 - accuracy: 0.5783\n",
            "Minimum loss =  0.8663988564072586\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.5442 - accuracy: 0.4024\n",
            "Minimum loss =  6.010473932538714\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1114 - accuracy: 0.3976\n",
            "Minimum loss =  3.0302560096833764\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9863 - accuracy: 0.5301\n",
            "Minimum loss =  1.534795516874732\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.1615 - accuracy: 0.3659\n",
            "Minimum loss =  0.9497071845190865\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7199 - accuracy: 0.6867\n",
            "Minimum loss =  0.7790426735470934\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1351 - accuracy: 0.6867\n",
            "Minimum loss =  0.5589543554659296\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.8841 - accuracy: 0.4878\n",
            "Minimum loss =  2.9792413598015193\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2485 - accuracy: 0.6386\n",
            "Minimum loss =  2.551361560821533\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5506 - accuracy: 0.6386\n",
            "Minimum loss =  1.1309718678637248\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.8495 - accuracy: 0.3415\n",
            "Minimum loss =  3.1149512926737466\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9033 - accuracy: 0.5542\n",
            "Minimum loss =  1.598579508502309\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1733 - accuracy: 0.5663\n",
            "Minimum loss =  0.7535132605855058\n",
            "Epoch 1/1\n",
            " - 0s - loss: 13.4429 - accuracy: 0.3659\n",
            "Minimum loss =  0.8593455836886451\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7674 - accuracy: 0.6988\n",
            "Minimum loss =  2.3514470239964926\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6604 - accuracy: 0.5663\n",
            "Minimum loss =  0.36337773683594493\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.0700 - accuracy: 0.3049\n",
            "Minimum loss =  7.713749113537016\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.4682 - accuracy: 0.2651\n",
            "Minimum loss =  3.920702073632217\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4380 - accuracy: 0.3012\n",
            "Minimum loss =  1.57882417411339\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.4908 - accuracy: 0.3780\n",
            "Minimum loss =  6.36348937806629\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5762 - accuracy: 0.4699\n",
            "Minimum loss =  1.3954320477276314\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0395 - accuracy: 0.6386\n",
            "Minimum loss =  0.5854314013225276\n",
            "Epoch 1/1\n",
            " - 0s - loss: 29.4039 - accuracy: 0.3293\n",
            "Minimum loss =  1.2826610860370455\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1389 - accuracy: 0.6024\n",
            "Minimum loss =  0.7052725757040629\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6521 - accuracy: 0.7590\n",
            "Minimum loss =  0.5014442845088679\n",
            "Epoch 1/1\n",
            " - 0s - loss: 28.0630 - accuracy: 0.4024\n",
            "Minimum loss =  18.37431544349307\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.2329 - accuracy: 0.2410\n",
            "Minimum loss =  0.7318599631146687\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6625 - accuracy: 0.7470\n",
            "Minimum loss =  1.450093802882404\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.2337 - accuracy: 0.4634\n",
            "Minimum loss =  4.761200791313534\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6625 - accuracy: 0.5301\n",
            "Minimum loss =  1.3811861887210752\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0333 - accuracy: 0.6867\n",
            "Minimum loss =  1.2317009059394277\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.5725 - accuracy: 0.4512\n",
            "Minimum loss =  1.3300586087363107\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1415 - accuracy: 0.5783\n",
            "Minimum loss =  1.4614751542486795\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0278 - accuracy: 0.6265\n",
            "Minimum loss =  1.4819428557302894\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.1786 - accuracy: 0.3902\n",
            "Minimum loss =  2.6504356179918562\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4480 - accuracy: 0.6506\n",
            "Minimum loss =  0.8427744318799275\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8036 - accuracy: 0.7349\n",
            "Minimum loss =  0.8170717809258438\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.6531 - accuracy: 0.2683\n",
            "Minimum loss =  2.049229065577189\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3864 - accuracy: 0.6627\n",
            "Minimum loss =  0.968099288824128\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6819 - accuracy: 0.5783\n",
            "Minimum loss =  1.348342363427325\n",
            "Epoch 1/1\n",
            " - 0s - loss: 89.3346 - accuracy: 0.3659\n",
            "Minimum loss =  27.612234388078964\n",
            "Epoch 1/1\n",
            " - 0s - loss: 22.6033 - accuracy: 0.3373\n",
            "Minimum loss =  2.1473427400356386\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4270 - accuracy: 0.5542\n",
            "Minimum loss =  1.0484708344064109\n",
            "Epoch 1/1\n",
            " - 0s - loss: 47.0086 - accuracy: 0.2927\n",
            "Minimum loss =  18.61257589431036\n",
            "Epoch 1/1\n",
            " - 0s - loss: 13.5971 - accuracy: 0.5422\n",
            "Minimum loss =  1.3918657361007318\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3487 - accuracy: 0.6265\n",
            "Minimum loss =  2.2712477707281344\n",
            "Epoch 1/1\n",
            " - 0s - loss: 109.1830 - accuracy: 0.4024\n",
            "Minimum loss =  1.9009088845480056\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5209 - accuracy: 0.5301\n",
            "Minimum loss =  0.8598130040052461\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8046 - accuracy: 0.6867\n",
            "Minimum loss =  0.8391160499758836\n",
            "Epoch 1/1\n",
            " - 0s - loss: 33.1235 - accuracy: 0.3659\n",
            "Minimum loss =  6.900145212809245\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1735 - accuracy: 0.3253\n",
            "Minimum loss =  1.5544988789209506\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4325 - accuracy: 0.6867\n",
            "Minimum loss =  0.3633279480585238\n",
            "Epoch 1/1\n",
            " - 0s - loss: 16.4451 - accuracy: 0.4512\n",
            "Minimum loss =  7.952900863829113\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0745 - accuracy: 0.5422\n",
            "Minimum loss =  5.161167621612549\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.8512 - accuracy: 0.5181\n",
            "Minimum loss =  5.144857232163592\n",
            "Epoch 1/1\n",
            " - 0s - loss: 70.2759 - accuracy: 0.3780\n",
            "Minimum loss =  16.46304566519601\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.6114 - accuracy: 0.4819\n",
            "Minimum loss =  0.5639119140985536\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.5175 - accuracy: 0.8434\n",
            "Minimum loss =  1.2398222219653245\n",
            "Epoch 1/1\n",
            " - 0s - loss: 86.1933 - accuracy: 0.2561\n",
            "Minimum loss =  1.300894944440751\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2974 - accuracy: 0.7229\n",
            "Minimum loss =  2.126272721988399\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3457 - accuracy: 0.5663\n",
            "Minimum loss =  1.0983941584098629\n",
            "Epoch 1/1\n",
            " - 0s - loss: 64.8999 - accuracy: 0.3537\n",
            "Minimum loss =  4.189091864086333\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.4023 - accuracy: 0.6747\n",
            "Minimum loss =  3.2872580900424864\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5458 - accuracy: 0.6867\n",
            "Minimum loss =  1.1310830755931576\n",
            "Epoch 1/1\n",
            " - 0s - loss: 38.5995 - accuracy: 0.3902\n",
            "Minimum loss =  5.139644963400705\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.2800 - accuracy: 0.6024\n",
            "Minimum loss =  3.4552676852156474\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5043 - accuracy: 0.5904\n",
            "Minimum loss =  3.4123410364476645\n",
            "Epoch 1/1\n",
            " - 0s - loss: 78.2553 - accuracy: 0.2561\n",
            "Minimum loss =  5.359380494980585\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.6629 - accuracy: 0.5422\n",
            "Minimum loss =  2.7762583290658345\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.5394 - accuracy: 0.5783\n",
            "Minimum loss =  0.8533993203465532\n",
            "Epoch 1/1\n",
            " - 0s - loss: 80.5488 - accuracy: 0.4024\n",
            "Minimum loss =  5.358066082000732\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.4703 - accuracy: 0.5422\n",
            "Minimum loss =  5.405884812517864\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.1619 - accuracy: 0.5181\n",
            "Minimum loss =  2.464797392124083\n",
            "Epoch 1/1\n",
            " - 0s - loss: 24.8521 - accuracy: 0.3902\n",
            "Minimum loss =  10.943563370477586\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4989 - accuracy: 0.5301\n",
            "Minimum loss =  3.6594345278856233\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4920 - accuracy: 0.5904\n",
            "Minimum loss =  3.9603386448650824\n",
            "Epoch 1/1\n",
            " - 0s - loss: 51.6312 - accuracy: 0.3415\n",
            "Minimum loss =  6.660862173352923\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.2782 - accuracy: 0.6265\n",
            "Minimum loss =  1.372177829102772\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3320 - accuracy: 0.6386\n",
            "Minimum loss =  0.403820020396535\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.8425 - accuracy: 0.4268\n",
            "Minimum loss =  1.3597593761625744\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9064 - accuracy: 0.7229\n",
            "Minimum loss =  2.109912180319065\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8159 - accuracy: 0.6506\n",
            "Minimum loss =  3.2210627125530706\n",
            "Epoch 1/1\n",
            " - 0s - loss: 80.3621 - accuracy: 0.4146\n",
            "Minimum loss =  4.354913257417225\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5862 - accuracy: 0.5663\n",
            "Minimum loss =  2.622259003360097\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8583 - accuracy: 0.6506\n",
            "Minimum loss =  2.2106202404673505\n",
            "Epoch 1/1\n",
            " - 0s - loss: 37.8786 - accuracy: 0.3415\n",
            "Minimum loss =  2.7281508105141774\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4014 - accuracy: 0.7590\n",
            "Minimum loss =  5.132188878408292\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8218 - accuracy: 0.7108\n",
            "Minimum loss =  1.559623889806794\n",
            "Epoch 1/1\n",
            " - 0s - loss: 70.2416 - accuracy: 0.3537\n",
            "Minimum loss =  2.2291584809621177\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8305 - accuracy: 0.6988\n",
            "Minimum loss =  0.9316251128003364\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8977 - accuracy: 0.8434\n",
            "Minimum loss =  1.6461476174796499\n",
            "Epoch 1/1\n",
            " - 0s - loss: 34.2846 - accuracy: 0.3049\n",
            "Minimum loss =  4.386223395665486\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4595 - accuracy: 0.5301\n",
            "Minimum loss =  2.2624856378973983\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2291 - accuracy: 0.6506\n",
            "Minimum loss =  1.537568788702895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 121.4213 - accuracy: 0.2927\n",
            "Minimum loss =  22.72707058134533\n",
            "Epoch 1/1\n",
            " - 0s - loss: 13.6761 - accuracy: 0.1807\n",
            "Minimum loss =  5.240636860452047\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2342 - accuracy: 0.6867\n",
            "Minimum loss =  2.2568300846146374\n",
            "Epoch 1/1\n",
            " - 0s - loss: 44.4544 - accuracy: 0.3659\n",
            "Minimum loss =  3.805847962697347\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4545 - accuracy: 0.5301\n",
            "Minimum loss =  2.4907772366593526\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.0283 - accuracy: 0.6867\n",
            "Minimum loss =  3.424229389283715\n",
            "Epoch 1/1\n",
            " - 0s - loss: 84.8014 - accuracy: 0.4146\n",
            "Minimum loss =  5.7603044509887695\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.2148 - accuracy: 0.5301\n",
            "Minimum loss =  4.511043426467151\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.9875 - accuracy: 0.5663\n",
            "Minimum loss =  2.4965746926098333\n",
            "Epoch 1/1\n",
            " - 0s - loss: 47.7495 - accuracy: 0.4268\n",
            "Minimum loss =  2.409444820313227\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9085 - accuracy: 0.6386\n",
            "Minimum loss =  1.639000843937804\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4779 - accuracy: 0.7349\n",
            "Minimum loss =  2.370811724081272\n",
            "Epoch 1/1\n",
            " - 0s - loss: 88.6290 - accuracy: 0.3780\n",
            "Minimum loss =  39.410279410226\n",
            "Epoch 1/1\n",
            " - 0s - loss: 38.0213 - accuracy: 0.4578\n",
            "Minimum loss =  8.054597214954656\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0290 - accuracy: 0.6867\n",
            "Minimum loss =  4.715399125727211\n",
            "Epoch 1/1\n",
            " - 0s - loss: 45.6968 - accuracy: 0.4146\n",
            "Minimum loss =  10.189570472353982\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.0763 - accuracy: 0.2771\n",
            "Minimum loss =  3.256268594323135\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.1344 - accuracy: 0.4578\n",
            "Minimum loss =  5.052887986345989\n",
            "Epoch 1/1\n",
            " - 0s - loss: 149.3537 - accuracy: 0.2683\n",
            "Minimum loss =  2.782670157296317\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3588 - accuracy: 0.6506\n",
            "Minimum loss =  1.020779417782295\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1435 - accuracy: 0.6747\n",
            "Minimum loss =  0.7875879813985127\n",
            "Epoch 1/1\n",
            " - 0s - loss: 69.4474 - accuracy: 0.3293\n",
            "Minimum loss =  18.413472675141833\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.4958 - accuracy: 0.1446\n",
            "Minimum loss =  1.7991204959590261\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1728 - accuracy: 0.6265\n",
            "Minimum loss =  1.106768235927675\n",
            "Epoch 1/1\n",
            " - 0s - loss: 247.0475 - accuracy: 0.4146\n",
            "Minimum loss =  1.296545391991025\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9321 - accuracy: 0.6265\n",
            "Minimum loss =  0.5916502824643763\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7396 - accuracy: 0.7108\n",
            "Minimum loss =  0.9876760128067761\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.0762 - accuracy: 0.4390\n",
            "Minimum loss =  2.47687638373602\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5927 - accuracy: 0.5542\n",
            "Minimum loss =  0.8479943449904279\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1495 - accuracy: 0.6145\n",
            "Minimum loss =  1.0474023749915564\n",
            "Epoch 1/1\n",
            " - 0s - loss: 40.6449 - accuracy: 0.3415\n",
            "Minimum loss =  4.652948969886417\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.4164 - accuracy: 0.4819\n",
            "Minimum loss =  1.7563731292398965\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5001 - accuracy: 0.6627\n",
            "Minimum loss =  1.46181324342402\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.8867 - accuracy: 0.3293\n",
            "Minimum loss =  1.107349163010007\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0952 - accuracy: 0.6627\n",
            "Minimum loss =  0.7259412451488215\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8084 - accuracy: 0.6988\n",
            "Minimum loss =  1.1675887645744696\n",
            "Epoch 1/1\n",
            " - 0s - loss: 37.0803 - accuracy: 0.2561\n",
            "Minimum loss =  20.86872182573591\n",
            "Epoch 1/1\n",
            " - 0s - loss: 17.6397 - accuracy: 0.1687\n",
            "Minimum loss =  1.6836369764514085\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9137 - accuracy: 0.6024\n",
            "Minimum loss =  1.0992006775809497\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.2833 - accuracy: 0.4268\n",
            "Minimum loss =  1.16120103427342\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7882 - accuracy: 0.7349\n",
            "Minimum loss =  0.7108451971193639\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8030 - accuracy: 0.7470\n",
            "Minimum loss =  1.091287425378474\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.7117 - accuracy: 0.2805\n",
            "Minimum loss =  9.299057347433907\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.5605 - accuracy: 0.3976\n",
            "Minimum loss =  2.969045229074432\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6946 - accuracy: 0.3373\n",
            "Minimum loss =  1.5583638650615041\n",
            "Epoch 1/1\n",
            " - 0s - loss: 59.1879 - accuracy: 0.1829\n",
            "Minimum loss =  3.473561854589553\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6409 - accuracy: 0.5301\n",
            "Minimum loss =  1.9407063170177181\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5650 - accuracy: 0.6145\n",
            "Minimum loss =  1.0856427186872901\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.0241 - accuracy: 0.3171\n",
            "Minimum loss =  8.519996098109655\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.7943 - accuracy: 0.1928\n",
            "Minimum loss =  3.49617409124607\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9128 - accuracy: 0.4096\n",
            "Minimum loss =  2.26202377458898\n",
            "Epoch 1/1\n",
            " - 0s - loss: 45.7840 - accuracy: 0.2805\n",
            "Minimum loss =  1.4787826651618594\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4979 - accuracy: 0.6145\n",
            "Minimum loss =  2.776068984008417\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2780 - accuracy: 0.5542\n",
            "Minimum loss =  0.9543558940654848\n",
            "Epoch 1/1\n",
            " - 0s - loss: 83.9767 - accuracy: 0.3902\n",
            "Minimum loss =  7.318296932038807\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.1619 - accuracy: 0.2169\n",
            "Minimum loss =  1.5990862061337727\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2796 - accuracy: 0.4819\n",
            "Minimum loss =  0.7948904778899216\n",
            "Epoch 1/1\n",
            " - 0s - loss: 48.2050 - accuracy: 0.2439\n",
            "Minimum loss =  1.0798827239445277\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1612 - accuracy: 0.6627\n",
            "Minimum loss =  0.8960932580436148\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1152 - accuracy: 0.6506\n",
            "Minimum loss =  1.2799478623925187\n",
            "Epoch 1/1\n",
            " - 0s - loss: 251.6262 - accuracy: 0.3171\n",
            "Minimum loss =  6.674312614259266\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.3459 - accuracy: 0.2410\n",
            "Minimum loss =  3.0643600836032774\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2260 - accuracy: 0.3012\n",
            "Minimum loss =  1.0529578749726458\n",
            "Epoch 1/1\n",
            " - 0s - loss: 80.6447 - accuracy: 0.2561\n",
            "Minimum loss =  6.906746659960065\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.6100 - accuracy: 0.3494\n",
            "Minimum loss =  1.003907215304491\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0268 - accuracy: 0.5783\n",
            "Minimum loss =  1.2471663224987868\n",
            "Epoch 1/1\n",
            " - 0s - loss: 21.2877 - accuracy: 0.2927\n",
            "Minimum loss =  4.33983394077846\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.2591 - accuracy: 0.2892\n",
            "Minimum loss =  3.512991800540831\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.1843 - accuracy: 0.5060\n",
            "Minimum loss =  1.8096960361410932\n",
            "Epoch 1/1\n",
            " - 0s - loss: 143.6567 - accuracy: 0.2317\n",
            "Minimum loss =  2.2423436301095143\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9088 - accuracy: 0.5181\n",
            "Minimum loss =  1.5532821300553112\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4813 - accuracy: 0.5422\n",
            "Minimum loss =  1.343000013653825\n",
            "Epoch 1/1\n",
            " - 0s - loss: 164.5384 - accuracy: 0.4146\n",
            "Minimum loss =  6.404389915012178\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5163 - accuracy: 0.3373\n",
            "Minimum loss =  2.644868478542421\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2484 - accuracy: 0.3976\n",
            "Minimum loss =  0.8348200670102748\n",
            "Epoch 1/1\n",
            " - 0s - loss: 26.1764 - accuracy: 0.3537\n",
            "Minimum loss =  2.7481722831726074\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9478 - accuracy: 0.5422\n",
            "Minimum loss =  0.904360137334684\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8887 - accuracy: 0.6506\n",
            "Minimum loss =  1.010831792180131\n",
            "Epoch 1/1\n",
            " - 0s - loss: 31.6517 - accuracy: 0.2805\n",
            "Minimum loss =  0.9291760807945615\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7404 - accuracy: 0.7108\n",
            "Minimum loss =  0.578841514703704\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.4520 - accuracy: 0.8554\n",
            "Minimum loss =  1.2603459241913586\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1949 - accuracy: 0.4512\n",
            "Minimum loss =  2.55376630737668\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3701 - accuracy: 0.5181\n",
            "Minimum loss =  1.5006375894313906\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1913 - accuracy: 0.7349\n",
            "Minimum loss =  1.5105684501368826\n",
            "Epoch 1/1\n",
            " - 0s - loss: 27.1163 - accuracy: 0.3537\n",
            "Minimum loss =  4.959206126985096\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.7197 - accuracy: 0.5783\n",
            "Minimum loss =  1.250994827689194\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4978 - accuracy: 0.4578\n",
            "Minimum loss =  1.2709555393312035\n",
            "Epoch 1/1\n",
            " - 0s - loss: 62.1812 - accuracy: 0.4146\n",
            "Minimum loss =  3.427788257598877\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.2634 - accuracy: 0.4699\n",
            "Minimum loss =  1.0496429030488177\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8223 - accuracy: 0.6627\n",
            "Minimum loss =  1.1178007707363222\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.2744 - accuracy: 0.3293\n",
            "Minimum loss =  1.1502162388392858\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3710 - accuracy: 0.6024\n",
            "Minimum loss =  2.308136463165283\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8649 - accuracy: 0.5783\n",
            "Minimum loss =  3.71418066141082\n",
            "Epoch 1/1\n",
            " - 0s - loss: 46.9094 - accuracy: 0.2927\n",
            "Minimum loss =  11.781996045793806\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.3568 - accuracy: 0.4096\n",
            "Minimum loss =  1.4356971426707943\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3193 - accuracy: 0.6386\n",
            "Minimum loss =  1.0749534601118507\n",
            "Epoch 1/1\n",
            " - 0s - loss: 48.0062 - accuracy: 0.3293\n",
            "Minimum loss =  3.0385533287411643\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6547 - accuracy: 0.6024\n",
            "Minimum loss =  2.2074092771948837\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3721 - accuracy: 0.5422\n",
            "Minimum loss =  1.0469047383564274\n",
            "Epoch 1/1\n",
            " - 0s - loss: 19.2320 - accuracy: 0.4024\n",
            "Minimum loss =  5.11782853943961\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.6226 - accuracy: 0.3494\n",
            "Minimum loss =  1.5419039275588058\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4284 - accuracy: 0.5904\n",
            "Minimum loss =  2.145079444094402\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5275 - accuracy: 0.6098\n",
            "Minimum loss =  1.7442319960821242\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2575 - accuracy: 0.7108\n",
            "Minimum loss =  1.2919653872164285\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8624 - accuracy: 0.5783\n",
            "Minimum loss =  0.7379859264303998\n",
            "Epoch 1/1\n",
            " - 0s - loss: 39.8369 - accuracy: 0.3537\n",
            "Minimum loss =  4.5947075344267345\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.0138 - accuracy: 0.5060\n",
            "Minimum loss =  1.6939627426426584\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0998 - accuracy: 0.6145\n",
            "Minimum loss =  0.5948004417303132\n",
            "Epoch 1/1\n",
            " - 0s - loss: 61.0404 - accuracy: 0.2195\n",
            "Minimum loss =  18.743016379220144\n",
            "Epoch 1/1\n",
            " - 0s - loss: 17.4788 - accuracy: 0.6024\n",
            "Minimum loss =  3.0101966799759285\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.3261 - accuracy: 0.5301\n",
            "Minimum loss =  1.0392947807544615\n",
            "Epoch 1/1\n",
            " - 0s - loss: 75.2665 - accuracy: 0.3780\n",
            "Minimum loss =  19.195020766485307\n",
            "Epoch 1/1\n",
            " - 0s - loss: 17.2592 - accuracy: 0.1928\n",
            "Minimum loss =  7.02604612490026\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.1281 - accuracy: 0.3494\n",
            "Minimum loss =  0.6744340062141418\n",
            "Epoch 1/1\n",
            " - 0s - loss: 52.9553 - accuracy: 0.2805\n",
            "Minimum loss =  15.800293014163064\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.7420 - accuracy: 0.2048\n",
            "Minimum loss =  1.097866671841319\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9013 - accuracy: 0.6145\n",
            "Minimum loss =  0.9416947132203637\n",
            "Epoch 1/1\n",
            " - 0s - loss: 38.4088 - accuracy: 0.2439\n",
            "Minimum loss =  8.211775325593495\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.4357 - accuracy: 0.2410\n",
            "Minimum loss =  8.99549302822206\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.6724 - accuracy: 0.3855\n",
            "Minimum loss =  0.6579802443341511\n",
            "Epoch 1/1\n",
            " - 0s - loss: 17.8866 - accuracy: 0.3415\n",
            "Minimum loss =  0.939397625979923\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7858 - accuracy: 0.7470\n",
            "Minimum loss =  0.7362702634276413\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.4487 - accuracy: 0.8072\n",
            "Minimum loss =  1.5499026048474196\n",
            "Epoch 1/1\n",
            " - 0s - loss: 20.1523 - accuracy: 0.1098\n",
            "Minimum loss =  6.083337534041632\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.5425 - accuracy: 0.2410\n",
            "Minimum loss =  0.7390282328535871\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8166 - accuracy: 0.7470\n",
            "Minimum loss =  0.7886435302292428\n",
            "Epoch 1/1\n",
            " - 0s - loss: 13.4195 - accuracy: 0.3049\n",
            "Minimum loss =  5.319736889430454\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.2004 - accuracy: 0.3253\n",
            "Minimum loss =  1.6314077638998263\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2745 - accuracy: 0.5783\n",
            "Minimum loss =  0.6452445693132354\n",
            "Epoch 1/1\n",
            " - 0s - loss: 118.9021 - accuracy: 0.3780\n",
            "Minimum loss =  2.6886501766386486\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3230 - accuracy: 0.5422\n",
            "Minimum loss =  1.4296524175783483\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9280 - accuracy: 0.6506\n",
            "Minimum loss =  0.9945242332249153\n",
            "Epoch 1/1\n",
            " - 0s - loss: 20.3252 - accuracy: 0.3415\n",
            "Minimum loss =  1.0262119997115362\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6338 - accuracy: 0.7590\n",
            "Minimum loss =  1.190647657324628\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0760 - accuracy: 0.6386\n",
            "Minimum loss =  0.7513945553360916\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.4575 - accuracy: 0.4268\n",
            "Minimum loss =  4.758838154020763\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8104 - accuracy: 0.5542\n",
            "Minimum loss =  1.7198292714793508\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2393 - accuracy: 0.6506\n",
            "Minimum loss =  2.206918693170315\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.8869 - accuracy: 0.2317\n",
            "Minimum loss =  1.894748324439639\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4130 - accuracy: 0.6145\n",
            "Minimum loss =  2.5540578772382037\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5129 - accuracy: 0.6386\n",
            "Minimum loss =  1.3100696773063847\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.6154 - accuracy: 0.4024\n",
            "Minimum loss =  1.2836125180834816\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7648 - accuracy: 0.6988\n",
            "Minimum loss =  1.504304554404282\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7285 - accuracy: 0.7470\n",
            "Minimum loss =  0.7064723561449748\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.9849 - accuracy: 0.3293\n",
            "Minimum loss =  2.6556129342033747\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7806 - accuracy: 0.5542\n",
            "Minimum loss =  1.5175843936641042\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2531 - accuracy: 0.6145\n",
            "Minimum loss =  1.4545422995962747\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.6075 - accuracy: 0.5122\n",
            "Minimum loss =  1.8030132679712205\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6442 - accuracy: 0.6145\n",
            "Minimum loss =  1.4231803359054938\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8959 - accuracy: 0.7590\n",
            "Minimum loss =  1.6120564443309133\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.4485 - accuracy: 0.5122\n",
            "Minimum loss =  2.379110710961478\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6175 - accuracy: 0.5783\n",
            "Minimum loss =  0.839102945676664\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0218 - accuracy: 0.6506\n",
            "Minimum loss =  1.6951049333665429\n",
            "Epoch 1/1\n",
            " - 0s - loss: 16.2559 - accuracy: 0.3537\n",
            "Minimum loss =  1.1862052508762904\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8763 - accuracy: 0.6867\n",
            "Minimum loss =  0.658003568649292\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7896 - accuracy: 0.7108\n",
            "Minimum loss =  2.419425534039009\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.5431 - accuracy: 0.4634\n",
            "Minimum loss =  1.7520212332407634\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7958 - accuracy: 0.5422\n",
            "Minimum loss =  1.3137843114573782\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4735 - accuracy: 0.5422\n",
            "Minimum loss =  1.201951009471242\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.4496 - accuracy: 0.4390\n",
            "Minimum loss =  1.2160294850667317\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0090 - accuracy: 0.6988\n",
            "Minimum loss =  1.9004963723624624\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2303 - accuracy: 0.6145\n",
            "Minimum loss =  1.4043913788911773\n",
            "Epoch 1/1\n",
            " - 0s - loss: 66.4085 - accuracy: 0.3780\n",
            "Minimum loss =  1.8458646819705056\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3672 - accuracy: 0.6386\n",
            "Minimum loss =  1.2075657931769765\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0807 - accuracy: 0.6145\n",
            "Minimum loss =  0.6628771787736474\n",
            "Epoch 1/1\n",
            " - 0s - loss: 19.6759 - accuracy: 0.3171\n",
            "Minimum loss =  1.2937397105353219\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6564 - accuracy: 0.6988\n",
            "Minimum loss =  0.8559285751203212\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9078 - accuracy: 0.7590\n",
            "Minimum loss =  0.4492092779496821\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.7955 - accuracy: 0.3659\n",
            "Minimum loss =  2.078730276652745\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3748 - accuracy: 0.6627\n",
            "Minimum loss =  2.170669014860944\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6138 - accuracy: 0.6747\n",
            "Minimum loss =  0.44455115969588116\n",
            "Epoch 1/1\n",
            " - 0s - loss: 33.1754 - accuracy: 0.3293\n",
            "Minimum loss =  8.379970936548142\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.3287 - accuracy: 0.5301\n",
            "Minimum loss =  2.9517678109610954\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8181 - accuracy: 0.5542\n",
            "Minimum loss =  1.1240646083180497\n",
            "Epoch 1/1\n",
            " - 0s - loss: 96.2193 - accuracy: 0.4268\n",
            "Minimum loss =  1.8070686544690813\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6668 - accuracy: 0.6747\n",
            "Minimum loss =  1.1665911383745147\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.7060 - accuracy: 0.7590\n",
            "Minimum loss =  0.6862391844028379\n",
            "Epoch 1/1\n",
            " - 0s - loss: 20.6154 - accuracy: 0.3415\n",
            "Minimum loss =  2.804644607362293\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3295 - accuracy: 0.4699\n",
            "Minimum loss =  0.9663595833429476\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6435 - accuracy: 0.7349\n",
            "Minimum loss =  1.70437259790374\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.2403 - accuracy: 0.3293\n",
            "Minimum loss =  9.331830615089054\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.7374 - accuracy: 0.3373\n",
            "Minimum loss =  1.9851460224244653\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.8673 - accuracy: 0.4699\n",
            "Minimum loss =  1.058079175832795\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.2199 - accuracy: 0.3780\n",
            "Minimum loss =  4.729456765311105\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.2212 - accuracy: 0.5181\n",
            "Minimum loss =  2.9592083721626095\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9419 - accuracy: 0.5904\n",
            "Minimum loss =  0.5932736338638678\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.8213 - accuracy: 0.4024\n",
            "Minimum loss =  2.5034782659439814\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6546 - accuracy: 0.5301\n",
            "Minimum loss =  1.049491335706013\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2472 - accuracy: 0.6867\n",
            "Minimum loss =  1.0783625114254836\n",
            "Epoch 1/1\n",
            " - 0s - loss: 81.4901 - accuracy: 0.2561\n",
            "Minimum loss =  46.60916973295666\n",
            "Epoch 1/1\n",
            " - 0s - loss: 27.6816 - accuracy: 0.3253\n",
            "Minimum loss =  2.1679744720458984\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7675 - accuracy: 0.4819\n",
            "Minimum loss =  1.164888373235377\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.8744 - accuracy: 0.3780\n",
            "Minimum loss =  0.6602617317721957\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6565 - accuracy: 0.7952\n",
            "Minimum loss =  1.726861628090463\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3765 - accuracy: 0.5904\n",
            "Minimum loss =  1.4726752653354551\n",
            "Epoch 1/1\n",
            " - 0s - loss: 31.3295 - accuracy: 0.3415\n",
            "Minimum loss =  7.3641590390886575\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.7215 - accuracy: 0.5663\n",
            "Minimum loss =  3.55886188367518\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2347 - accuracy: 0.6988\n",
            "Minimum loss =  2.452777964312856\n",
            "Epoch 1/1\n",
            " - 0s - loss: 45.7547 - accuracy: 0.4268\n",
            "Minimum loss =  11.44036206744966\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.3077 - accuracy: 0.6265\n",
            "Minimum loss =  9.553947669703787\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.8698 - accuracy: 0.6024\n",
            "Minimum loss =  3.9045873967612663\n",
            "Epoch 1/1\n",
            " - 0s - loss: 36.4980 - accuracy: 0.3537\n",
            "Minimum loss =  6.215888500213623\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.5019 - accuracy: 0.3855\n",
            "Minimum loss =  1.7429690709928187\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1559 - accuracy: 0.7349\n",
            "Minimum loss =  1.7226072229990146\n",
            "Epoch 1/1\n",
            " - 0s - loss: 32.8842 - accuracy: 0.3171\n",
            "Minimum loss =  6.586391040257046\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5025 - accuracy: 0.6386\n",
            "Minimum loss =  0.7708697522558817\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.0961 - accuracy: 0.6747\n",
            "Minimum loss =  1.4490935569856225\n",
            "Epoch 1/1\n",
            " - 0s - loss: 40.3531 - accuracy: 0.3049\n",
            "Minimum loss =  2.935647067569551\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2298 - accuracy: 0.6506\n",
            "Minimum loss =  2.3651507714899576\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6282 - accuracy: 0.7229\n",
            "Minimum loss =  5.935490829188649\n",
            "Epoch 1/1\n",
            " - 0s - loss: 23.7618 - accuracy: 0.2683\n",
            "Minimum loss =  4.765205792018345\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.3224 - accuracy: 0.6145\n",
            "Minimum loss =  1.4292526128815441\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3195 - accuracy: 0.6747\n",
            "Minimum loss =  4.056381760573968\n",
            "Epoch 1/1\n",
            " - 0s - loss: 24.2435 - accuracy: 0.3415\n",
            "Minimum loss =  5.435659499395461\n",
            "Epoch 1/1\n",
            " - 0s - loss: 12.0269 - accuracy: 0.4217\n",
            "Minimum loss =  7.435572577685845\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.7723 - accuracy: 0.5181\n",
            "Minimum loss =  5.0172108876995924\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.1514 - accuracy: 0.3902\n",
            "Minimum loss =  11.863031886872792\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.2646 - accuracy: 0.5663\n",
            "Minimum loss =  7.23473639604522\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.4018 - accuracy: 0.5422\n",
            "Minimum loss =  2.3873546327032695\n",
            "Epoch 1/1\n",
            " - 0s - loss: 26.4562 - accuracy: 0.2683\n",
            "Minimum loss =  5.231594903128488\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.1219 - accuracy: 0.6386\n",
            "Minimum loss =  4.584331105395061\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.2393 - accuracy: 0.4940\n",
            "Minimum loss =  6.259628214487216\n",
            "Epoch 1/1\n",
            " - 0s - loss: 18.4596 - accuracy: 0.3780\n",
            "Minimum loss =  17.626585460844495\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.0447 - accuracy: 0.4217\n",
            "Minimum loss =  2.424530564284906\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.7619 - accuracy: 0.7229\n",
            "Minimum loss =  1.3214673327236641\n",
            "Epoch 1/1\n",
            " - 0s - loss: 14.9635 - accuracy: 0.3780\n",
            "Minimum loss =  14.889474096752348\n",
            "Epoch 1/1\n",
            " - 0s - loss: 10.3697 - accuracy: 0.4940\n",
            "Minimum loss =  4.134038302956558\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.0811 - accuracy: 0.7229\n",
            "Minimum loss =  1.370865094952467\n",
            "Epoch 1/1\n",
            " - 0s - loss: 23.1816 - accuracy: 0.3171\n",
            "Minimum loss =  1.8428681577954973\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.1530 - accuracy: 0.6627\n",
            "Minimum loss =  3.525841201223978\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.1479 - accuracy: 0.6747\n",
            "Minimum loss =  2.1499489458595833\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.8632 - accuracy: 0.2073\n",
            "Minimum loss =  3.9417082582201277\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.8335 - accuracy: 0.5663\n",
            "Minimum loss =  4.215495301455986\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.4126 - accuracy: 0.5663\n",
            "Minimum loss =  5.568032008845631\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.6683 - accuracy: 0.3780\n",
            "Minimum loss =  8.94417989821661\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.9864 - accuracy: 0.5060\n",
            "Minimum loss =  3.0413581278265975\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4327 - accuracy: 0.6747\n",
            "Minimum loss =  3.242298550722076\n",
            "Epoch 1/1\n",
            " - 0s - loss: 20.7394 - accuracy: 0.3171\n",
            "Minimum loss =  5.577022416251046\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0740 - accuracy: 0.5181\n",
            "Minimum loss =  2.217794374721806\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1452 - accuracy: 0.7108\n",
            "Minimum loss =  2.175131948982797\n",
            "Epoch 1/1\n",
            " - 0s - loss: 26.4828 - accuracy: 0.4024\n",
            "Minimum loss =  3.8563119229816256\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8215 - accuracy: 0.5663\n",
            "Minimum loss =  14.855774553810678\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.4490 - accuracy: 0.5783\n",
            "Minimum loss =  5.576807097690861\n",
            "Epoch 1/1\n",
            " - 0s - loss: 29.9796 - accuracy: 0.2927\n",
            "Minimum loss =  4.410582599185762\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.5299 - accuracy: 0.6627\n",
            "Minimum loss =  1.4219621565283798\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5189 - accuracy: 0.7831\n",
            "Minimum loss =  0.6672471986129517\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.9542 - accuracy: 0.3415\n",
            "Minimum loss =  8.927679970150901\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.6259 - accuracy: 0.4578\n",
            "Minimum loss =  3.606794770171003\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6389 - accuracy: 0.6627\n",
            "Minimum loss =  1.9783665814050815\n",
            "Epoch 1/1\n",
            " - 0s - loss: 46.3706 - accuracy: 0.3171\n",
            "Minimum loss =  29.859267371041433\n",
            "Epoch 1/1\n",
            " - 0s - loss: 21.6799 - accuracy: 0.3253\n",
            "Minimum loss =  12.439246107892293\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.3015 - accuracy: 0.5663\n",
            "Minimum loss =  4.983624853738925\n",
            "Epoch 1/1\n",
            " - 0s - loss: 22.4704 - accuracy: 0.3902\n",
            "Minimum loss =  42.76997666131882\n",
            "Epoch 1/1\n",
            " - 0s - loss: 23.8880 - accuracy: 0.4337\n",
            "Minimum loss =  3.5540527076255986\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.9488 - accuracy: 0.5181\n",
            "Minimum loss =  1.3375819717965476\n",
            "Epoch 1/1\n",
            " - 0s - loss: 23.0127 - accuracy: 0.3902\n",
            "Minimum loss =  19.727755591982888\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.8002 - accuracy: 0.4337\n",
            "Minimum loss =  22.176020924637957\n",
            "Epoch 1/1\n",
            " - 0s - loss: 19.6087 - accuracy: 0.5663\n",
            "Minimum loss =  9.031630260188406\n",
            "Epoch 1/1\n",
            " - 0s - loss: 28.1151 - accuracy: 0.2561\n",
            "Minimum loss =  14.677710487729026\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.3031 - accuracy: 0.5542\n",
            "Minimum loss =  2.5630838580247834\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8638 - accuracy: 0.5663\n",
            "Minimum loss =  3.4818282941492593\n",
            "Epoch 1/1\n",
            " - 0s - loss: 32.6627 - accuracy: 0.4146\n",
            "Minimum loss =  4.639126913888114\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.9299 - accuracy: 0.6988\n",
            "Minimum loss =  4.989930280824987\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.3183 - accuracy: 0.6506\n",
            "Minimum loss =  2.4684141234653754\n",
            "Epoch 1/1\n",
            " - 0s - loss: 32.5280 - accuracy: 0.3293\n",
            "Minimum loss =  5.261838583719163\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5464 - accuracy: 0.6506\n",
            "Minimum loss =  1.5629048529194622\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.3101 - accuracy: 0.6867\n",
            "Minimum loss =  2.4924770448266007\n",
            "Epoch 1/1\n",
            " - 0s - loss: 41.2916 - accuracy: 0.3171\n",
            "Minimum loss =  39.8681884039016\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.7520 - accuracy: 0.4458\n",
            "Minimum loss =  10.639760808246892\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.9463 - accuracy: 0.5301\n",
            "Minimum loss =  3.3824931295906624\n",
            "Epoch 1/1\n",
            " - 0s - loss: 38.4538 - accuracy: 0.3902\n",
            "Minimum loss =  14.594419615609306\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0365 - accuracy: 0.6627\n",
            "Minimum loss =  1.9186669966069663\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8169 - accuracy: 0.6506\n",
            "Minimum loss =  2.767523724858354\n",
            "Epoch 1/1\n",
            " - 0s - loss: 27.3935 - accuracy: 0.3415\n",
            "Minimum loss =  3.75329403650193\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.2276 - accuracy: 0.6747\n",
            "Minimum loss =  7.3253460279325155\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.2236 - accuracy: 0.6024\n",
            "Minimum loss =  1.0692002700596321\n",
            "Epoch 1/1\n",
            " - 0s - loss: 27.6749 - accuracy: 0.4268\n",
            "Minimum loss =  10.42052564166841\n",
            "Epoch 1/1\n",
            " - 0s - loss: 11.8124 - accuracy: 0.5301\n",
            "Minimum loss =  3.7134518739653797\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.6869 - accuracy: 0.6145\n",
            "Minimum loss =  8.577206239467714\n",
            "Epoch 1/1\n",
            " - 0s - loss: 29.1292 - accuracy: 0.3171\n",
            "Minimum loss =  6.1428680419921875\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.2053 - accuracy: 0.4940\n",
            "Minimum loss =  4.909357536129836\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.5905 - accuracy: 0.6867\n",
            "Minimum loss =  3.2402206165034597\n",
            "Epoch 1/1\n",
            " - 0s - loss: 42.8587 - accuracy: 0.3293\n",
            "Minimum loss =  1.5512213309605916\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5002 - accuracy: 0.6145\n",
            "Minimum loss =  4.161760969859798\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.9786 - accuracy: 0.6627\n",
            "Minimum loss =  2.7524797858261483\n",
            "Epoch 1/1\n",
            " - 0s - loss: 35.5775 - accuracy: 0.3415\n",
            "Minimum loss =  22.309144701276505\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.7857 - accuracy: 0.4096\n",
            "Minimum loss =  5.244601866094078\n",
            "Epoch 1/1\n",
            " - 0s - loss: 2.8067 - accuracy: 0.6386\n",
            "Minimum loss =  2.8770045943376497\n",
            "Epoch 1/1\n",
            " - 0s - loss: 43.4480 - accuracy: 0.3780\n",
            "Minimum loss =  31.95358657836914\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.5932 - accuracy: 0.4217\n",
            "Minimum loss =  2.2635542008934952\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0263 - accuracy: 0.6024\n",
            "Minimum loss =  3.779590641579977\n",
            "Epoch 1/1\n",
            " - 0s - loss: 41.9856 - accuracy: 0.2927\n",
            "Minimum loss =  5.94295410882859\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.7796 - accuracy: 0.5663\n",
            "Minimum loss =  5.792256960054723\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.6994 - accuracy: 0.6386\n",
            "Minimum loss =  2.0608742178940194\n",
            "Epoch 1/1\n",
            " - 0s - loss: 47.9942 - accuracy: 0.3537\n",
            "Minimum loss =  1.8280881700061618\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.4750 - accuracy: 0.7108\n",
            "Minimum loss =  2.672741511972939\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.9292 - accuracy: 0.7349\n",
            "Minimum loss =  0.4005591186081491\n",
            "Epoch 1/1\n",
            " - 0s - loss: 33.7037 - accuracy: 0.4390\n",
            "Minimum loss =  7.145117464519682\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.1885 - accuracy: 0.5060\n",
            "Minimum loss =  5.100624200774402\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.0362 - accuracy: 0.5663\n",
            "Minimum loss =  2.7705100338633466\n",
            "Epoch 1/1\n",
            " - 0s - loss: 30.2001 - accuracy: 0.3659\n",
            "Minimum loss =  13.659403800964355\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.1116 - accuracy: 0.5783\n",
            "Minimum loss =  4.69297031076943\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.3382 - accuracy: 0.6145\n",
            "Minimum loss =  6.813128773759051\n",
            "Epoch 1/1\n",
            " - 0s - loss: 64.7548 - accuracy: 0.2927\n",
            "Minimum loss =  9.433137814203898\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.7968 - accuracy: 0.4578\n",
            "Minimum loss =  12.479897917770758\n",
            "Epoch 1/1\n",
            " - 0s - loss: 15.0989 - accuracy: 0.5181\n",
            "Minimum loss =  2.136002232979347\n",
            "Epoch 1/1\n",
            " - 0s - loss: 25.6707 - accuracy: 0.4268\n",
            "Minimum loss =  3.0286202430725098\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.0480 - accuracy: 0.6145\n",
            "Minimum loss =  7.208929021184037\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.9797 - accuracy: 0.6265\n",
            "Minimum loss =  3.69087651880776\n",
            "Epoch 1/1\n",
            " - 0s - loss: 31.1050 - accuracy: 0.3171\n",
            "Minimum loss =  5.164525122869582\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.6648 - accuracy: 0.6265\n",
            "Minimum loss =  7.66977837027573\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.9415 - accuracy: 0.5783\n",
            "Minimum loss =  1.9993551417094906\n",
            "Epoch 1/1\n",
            " - 0s - loss: 21.3193 - accuracy: 0.4024\n",
            "Minimum loss =  5.785337879544213\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.9545 - accuracy: 0.5181\n",
            "Minimum loss =  3.9836550340419863\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.5827 - accuracy: 0.5904\n",
            "Minimum loss =  2.055203798340588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yffD5ng3CKH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe150831-b023-4304-b532-d03f59f38bf0"
      },
      "source": [
        "# Looking for best model parameters\n",
        "pn = 0\n",
        "aa = 0\n",
        "para_idx = []\n",
        "acc_dist = []\n",
        "for i,a,epochs in acc:\n",
        "  if i == 0:\n",
        "    pn +=1\n",
        "  if a>aa:\n",
        "    aa = a\n",
        "    ba = pn\n",
        "    be = epochs\n",
        "  para_idx.append(pn)\n",
        "  acc_dist.append(a*100)\n",
        "\n",
        "print(\"Best parameter was: leraning rate - \",hyper_para[ba-1][0],\", no.of neurons - \",hyper_para[ba-1][1],\"Epochs - \",be,\"With accuracy of  \",aa*100,\"%\")\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter was: leraning rate -  0.001 , no.of neurons -  52 Epochs -  3 With accuracy of   95.12194991111755 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wu-anARnUDd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "44272e5d-6f18-4dce-9f7f-0211928215a9"
      },
      "source": [
        "# Box Plot \n",
        "para_idx = np.array(para_idx).reshape(200,1)\n",
        "acc_dist = np.array(acc_dist).reshape(200,1)\n",
        "dd = np.concatenate((para_idx,acc_dist),axis=1)\n",
        "dd = pd.DataFrame(data=dd, columns=[\"Hyper_Para\", \"Accuracy\"])\n",
        "ax = sns.boxplot(x=\"Hyper_Para\", y=\"Accuracy\",data = dd)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM6RKnGloV1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6bd6328c-d746-4659-f056-a1441a9f43e0"
      },
      "source": [
        "#Best Model\n",
        "model = classification_model(hyper_para[ba-1][1])\n",
        "opt = optimizers.Adam(lr = hyper_para[ba-1][0])\n",
        "model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_201\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_201 (InputLayer)       (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_401 (Dense)            (None, 52)                728       \n",
            "_________________________________________________________________\n",
            "dense_402 (Dense)            (None, 3)                 159       \n",
            "=================================================================\n",
            "Total params: 887\n",
            "Trainable params: 887\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_psy-POoW8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "35677489-df11-45da-fd6b-6346d532e8ec"
      },
      "source": [
        "# Fitting on Best Model\n",
        "history = model.fit( X_train, Y_train,batch_size=10,verbose=2,shuffle= True)\n",
        "loss = history.history[\"loss\"][0]\n",
        "loss_dif = 1\n",
        "epoch = 1\n",
        "while loss_dif>1e-5:\n",
        "  history = model.fit( X_train[train], Y_train[train],batch_size=10,verbose=0,shuffle= True)\n",
        "  loss_dif = loss - history.history[\"loss\"][0]\n",
        "  loss = history.history[\"loss\"][0]\n",
        "  epoch +=1\n",
        "  print(epoch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 0s - loss: 283.4399 - accuracy: 0.4032\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS9K6buTq523",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdcefcf4-ce2a-44e5-86d2-b46b738ed6c8"
      },
      "source": [
        "# Evaluating model on Test Data\n",
        "scores = model.evaluate(X_test,Y_test,verbose=2)\n",
        "scores[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8703703880310059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPV93c0tZZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing Prediction\n",
        "predicted = model.predict(X_test)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejhW41VbyYti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating Rank\n",
        "final_pre_max = np.argmax(predicted, axis=1)\n",
        "Y_true_max = np.argmax(Y_test,axis=1)\n",
        "final_pre_min = np.argmin(predicted, axis=1)\n",
        "Y_true_min = np.argmin(Y_test,axis=1)\n",
        "rank1 = 0\n",
        "rank2 = 0\n",
        "rank3 = 0\n",
        "for i in range(len(Y_test)):\n",
        "  if final_pre_max[i]==Y_true_max[i]:\n",
        "    rank1 +=1\n",
        "  elif final_pre_min[i]==Y_true_max[i]:\n",
        "    rank3 +=1\n",
        "  else:\n",
        "    rank2 +=1\n",
        "rank2 +=rank1\n",
        "rank3 +=rank2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4eMtXdj8GQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "849477d2-2092-45e4-dda7-c139732d162e"
      },
      "source": [
        "# Plotting CMC Curve\n",
        "plt.plot([rank1/len(Y_test) , rank2/len(Y_test), rank3/len(Y_test)])\n",
        "plt.xlabel('Rank')\n",
        "plt.title('CMC curve on Wine Classification')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV_hUvkwFKTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}